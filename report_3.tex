%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Beamer Presentation
% LaTeX Template
% Version 1.0 (10/11/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND THEMES
%----------------------------------------------------------------------------------------

 \documentclass[handout]{beamer}
 %\documentclass{beamer}

\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line

}

\setbeamertemplate{footline}{%
	\leavevmode%
	\hbox{%
		\begin{beamercolorbox}[wd=.45\paperwidth,ht=2.25ex,dp=1ex,center]{author in head/foot}%
			\usebeamerfont{section in head/foot}\insertsection
		\end{beamercolorbox}%
		\begin{beamercolorbox}[wd=.22\paperwidth,ht=2.25ex,dp=1ex,center]{title in head/foot}%
			\usebeamerfont{title in head/foot}\insertshorttitle
		\end{beamercolorbox}%
		\begin{beamercolorbox}[wd=.3333\paperwidth,ht=2.25ex,dp=1ex,right]{date in head/foot}%
			\usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}
			\insertframenumber{} / \inserttotalframenumber\hspace*{2ex}
		\end{beamercolorbox}}%
		\vskip0pt%
	}


\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{amsmath}
\usepackage{mathrsfs}
\bibliographystyle{ieeetr}
\definecolor{bazaar}{rgb}{0.6, 0.47, 0.48}
\definecolor{grey}{rgb}{0.52, 0.52, 0.51}
%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Assignment3]{Assignment: 3-Achieving Usable and Privacy-assured Similarity Search over Outsourced Cloud Data} % The short title appears at the bottom of every slide, the full title is only on the title page

%\author{Author} % Your name
\author[Author, Another, Another] % (optional, use only with lots of authors)
{Dehai Wang \and \\Siyu Huang\and \\ Xinyi Li}
\institute[DLUT] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Dalian University of Technology \\
\textit{Assignment of System Security} % Your institution for the title page
\medskip % Your email address
}
\date{April 1, 2015} % Date, can be changed to a custom date

\begin{document}

\section{Introduction}
\begin{frame}
\titlepage % Print the title page as the first slide
\end{frame}

\begin{frame}
	\frametitle{Overview} % Table of contents slide, comment this block out to remove it
	\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}
\begin{frame}
	\frametitle{Introduction of the Paper}
	\bibliography{myreference}    
\end{frame}

\begin{frame}
 \frametitle{Introduction of the Paper}
 \begin{block}<1->{Purpose}
  Solve the problem of secure and efficient fuzzy search over encrypted outsourced cloud data
  \end{block}
  
  \begin{block}<2->{Measures}
  	\begin{itemize}
  		\item<3-> Suppressing technique 
  		\item<4-> Building a private trie-traverse searching index
  	\end{itemize}
  \end{block}
  
  \begin{block}<5->{Performance}
	  Correctly achieves the defined similarity search functionality with \textbf{\textcolor{red}{constant}}  searching time!
  \end{block}
  
  
\end{frame}


%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------
\section{Background} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------
\begin{frame}
	\frametitle{System and Threat Model}
	\begin{figure}
	\includegraphics[width=0.6\linewidth]{fig1.jpg}
	\caption[1]{Architecture of similarity keyword search over outsourced cloud data}
	\end{figure}
		\begin{itemize}
			\item<2-> data owner: the individual/enterprise customer,who has a collection of $n$ data files $C = ({F_1},{F_2}, \ldots ,{F_n})$ to be stored in the cloud server.
			\item<3-> $W = \left\{ {{w_i},{w_w}, \ldots ,{w_p}} \right\}$ is denoted as a predefined set of distinct keywords in $C$
		\end{itemize}
\end{frame}
%\subsection{Subsection Example} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks
\begin{frame}
	\frametitle{System and Threat Model}
	\begin{itemize}
		\item<1-> Files are encrypted before outsourced
		\item<2-> The data owner will distribute search request\textcolor{red}{(trapdoor) generation keys $sk$} to authorized users.(Assume that the authorization will be done appropriately)
		\item<3-> An authorized user uses \textcolor{red}{trapdoor generation key} to generate a search request via some \textcolor{red}{one-way function} to search word $w$, and submit it to the cloud.
		\item<4-> The cloud then performs the search over the data
		collection $C$ without decryption and sends back all encrypted files containing the specific keyword $w$, denoted as $FI{D_w}$.
		\item<5-> \textcolor{blue} {The
		similarity keyword search scheme returns the closest possible results based on aforementioned measures.}
		\item<6-> At last, the user decrypts files they received from the cloud.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Assumption: Honest-but-curious clound server}
    To ensure the securely similarity searching scheme:
    \begin{columns}[t] 
    \column{.3\textwidth}
    \begin{block}<2->{Honest}
    	Correctly follows the designated protocol specification
    \end{block}
    \column{.5\textwidth}
        \begin{alertblock}<3->{Curious}
        	Infer and analyze the message flow received during the protocol so as to learn additional information
        \end{alertblock}
    \end{columns}
    \begin{columns}
    \column{.8\textwidth}
    \begin{exampleblock}<4->{}
        We follow the security definition
        deployed in the traditional  \textcolor{red} {searchable symmetric encryption(SSE)}
    \end{exampleblock}
\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Notations}
	\begin{description}
		\item<2->[$C$]the file collection to be outsourced, denoted as a set of $n$ data files $C = ({F_1},{F_2}, \ldots ,{F_n})$.
		\item<3->[$W$]the distinct keywords extracted from file collection $C$, denoted as a set of $m$ words $W = \left\{ {{w_i},{w_w}, \ldots ,{w_p}} \right\}$.
		\item<4->[$\cal I$]the index built for privacy-assured similarity search.
		\item<5->[${T_w}$] the trapdoor generated by a user as a search request of input keyword $w$ via some one-way transformation.
		\item<6->[${S_{w,d}}$] similarity keyword set of $w$, where $d$ is the similarity threshold according to a certain similarity metrics.
		\item<7->[$FI{D_{{w_i}}}$]the set of identifiers of files in $C$ that contain keyword ${{w_i}}$.
		\item<8->[$f(key, \cdot ),g(key, \cdot )$]pseudorandom function (PRF), defined	as: ${\{ 0,1\} ^*} \times key \to {\{ 0,1\} ^{\ell }}$.
		\item<9->[$Enc(key, \cdot ),Dec(key, \cdot )$]symmetric key based semantic secure encryption/decryption function.
	\end{description}
\end{frame}
\section{Suppression Technique}
\begin{frame}
	\frametitle{Edit Distance}
	\begin{columns}
	\end{columns}
	\begin{block}<1->{Quantitative measurement}
		The edit distance $ed({w_1},{w_2})$ between two words ${w_1}$ and ${w_2}$ is the \textcolor{red}{minimum} number of \textcolor{red}{primitive operations}, including \textcolor{blue}{character insertion, deletion} and \textcolor{blue}{substitution}, necessary to transform one of them into the other.
	\end{block}
	
	\begin{block}<2->{Similarity keyword set}
		Given a keyword $w$, we let ${S_{w,d}}$ denote its similarity set of words, such that any $w' \in {S_{w,d}}$ satisfies \textcolor[rgb]{0.1,0.6,0.3}{$ed(w,w') \le d$}  for a certain integer $d$.
	\end{block}
	
	\begin{exampleblock}<3->{Example}
		Consider the keyword $w_0=$\textit{CENSOR}\\
		a words set W = \{\textit{CESOR},\textit{CENSER},\textit{CEANSOR}\}\\
		for any $w' \in W$,$ed({w_0},w') \le 1$ holds,\\
		i.e. $w' \in {S_{{w_0},1}}$ and $W \subseteq {S_{{w_0},1}}$
	\end{exampleblock}
\end{frame}

\begin{frame}
	\frametitle{Building Similarity Keyword Sets}
	\begin{columns}
		\column{.45\textwidth}
		\begin{alertblock}<2->{Straightforward approach}
			Simply \textcolor{red}{enumerating} all possible words $w{'_i}$ satisfying the similarity
			criteria $ed({w_i},w{'_i}) \le d$
		\end{alertblock}
		\begin{alertblock}<3->{}
		For the keyword $w_0=$\textit{CENSOR},
		consider just one substitution operation with charaters on first character.\\
		There are 26 items \{\textit{AENSOR},\textit{BENSOR}, \ldots ,\textit{YENSOR},\textit{ZENSOR}\} \\
		So ${S_{{w_0},1}}$ will be $[6 + (6 + 1)] \times \textcolor{red}{26} + \textcolor{green}1$
		\end{alertblock}
		\column{.5\textwidth}
		\begin{block}<4->{Suppression technique}
			Consider only the \textcolor{blue}{positions} of the primitive edit operations.Specifically, we use a \textcolor{blue}{wildcard ‘*’ }to
			denote all three operations of character insertion, deletion and
			substitution at any position.
		\end{block}
		
		\begin{block}<5->{}
			Now,\\
 ${{{S}}_{SENSOR,1}} = $ \{\textit{SENSOR}, \textit{*SENSOR, *ENSOR},\textit{S*ENSOR}, \textit{S*NSOR}, \ldots, \textit{SENSO*R}, \textit{SENSO*}, \textit{SENSOR*}\}.
			Size can be reduced to ${S_{{w_0},1}}$ will be $[6 + (6 + 1)] \times \textcolor{blue}{1} + \textcolor{green}1$
		\end{block}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Building Similarity Keyword Sets}
	\begin{figure}
		\includegraphics[width=0.4\linewidth]{algo1.jpg}
	\end{figure}
	The size of ${S_{{w_i},d}}$ will be ${\cal O}(\textcolor{blue}{\ell ^d})$,opposing to ${\cal O}(\textcolor{blue}{{\ell ^d}} \times \textcolor{red}{26^d})$ obtained in the \textcolor{red}{straightforward approach}.
\end{frame}

\begin{frame}
	\frametitle{Generating Searching Request}
	\begin{theorem}<2->
		The intersection of the similarity sets \textcolor{blue}{${S_{{w_i},d}}$} and \textcolor{red}{${S_{w,d}}$} for keyword \textcolor{blue}{$w_i$} and  search input \textcolor{red}{$w$} is not empty if and only if $ed(\textcolor{red}{w},\textcolor{blue}{w_i}) \le d$.
	\end{theorem}
	
	\begin{proof}<3->
		\begin{itemize}
			\item Completeness(i.e. $ed(\textcolor{red}{w},\textcolor{blue}{w_i}) \le d \to \textcolor{red}{S_{{w_i},d}} \cap \textcolor{blue}{S_{w,d}} \ne \emptyset $ ):
			\begin{itemize}[<4->]
				\item $\textcolor{red}{w} \to \textcolor{blue}{{w_i}}$ need at most $d$ primitive operations.\\the result after these operations is marked as $w^*$
				\item $w^*$ is naturally in \textcolor{red}{${S_{w,d}}$} 
				\item $w^*$ can be transformed into \textcolor{blue}{${w_i}$}, so it must be in \textcolor{blue}{${S_{{w_i},d}}$} 
				\item $w^* \in \textcolor{blue}{S_{{w_i},d}} \cap \textcolor{red}{S_{w,d}}$
			\end{itemize}
		\end{itemize}
	\end{proof}
\end{frame}


\begin{frame}
	\frametitle{Generating Searching Request}
	\begin{proof}
		\begin{itemize}
			\item Soundness(i.e. $\textcolor{blue}{S_{{w_i},d}} \cap \textcolor{red}{S_{w,d}} \ne \emptyset  \to ed(\textcolor{red}{w},\textcolor{blue}{w_i}) \le d$) \\
			\begin{description}[<2->]
				\item[${w^*}$]the common element in $\textcolor{blue}{S_{{w_i},d}} \cap \textcolor{red}{S_{w,d}}$
			\end{description}
			\begin{enumerate}
				\item<3-> ${w^*}$ does not contain any wildcard *,\\
				then ${w^*} =\textcolor{red}{ w} =\textcolor{blue}{ w'}$,and $ed(\textcolor{red}{w},\textcolor{blue}{w'}) = 0 \le d$
				\item<4-> ${w^*}$ does contain some wildcard *(at most d *'s),\\
				change * in $w^*$ back to the character in \textcolor{red}{$w$} and \textcolor{blue}{$w_i$},\\
				denote the result as \textcolor{red}{$w{'^*}$} and \textcolor{blue}{$w{'_i}^*$} with both sharing $d-1$ different *'s.\\
				$\textcolor{red}{w{'^*}} \to \textcolor{blue}{w{'_i}^*}$ need at most one primitive operation.\\
				So, $ed(\textcolor{red}{w{'^*}},\textcolor{blue}{w{'_i}^*}) \le 1$\\
				$ \Rightarrow ed(\textcolor{red}{w},\textcolor{blue}{{w_i}}) \le d$
				
			\end{enumerate}
		\end{itemize}
	\end{proof}
\end{frame}

\section{The Basic Scheme}

\begin{frame}
	\frametitle{The Basic Scheme}
	\begin{block}<2->{}
		\begin{description}
			\item[$\tau $]the maximum size of the similarity keyword set $S_{{w_i},d}$ for ${w_i} \in W$, i.e.,$\tau  = \max {\left\{ {\left| {{S_{{w_i},d}}} \right|} \right\}_{{w_i} \in W}}$ where $\left| W \right| = p$.
		\end{description}
	\end{block}
		\begin{exampleblock}<3->{Preprocessing phase(the owner)}
			\begin{enumerate}
				\item<4->  picks random key $x$,$y$,and builds index ${\cal I} = {\left\{ {\textcolor{red}{f(x,w{'_i})},Enc(\textcolor[rgb]{0.1,0.7,0.2}{s{k_{w{'_i}}}},FI{D_{{w_i}}})} \right\}_{w{'_i} \in {S_{{w_i},d}},1 \le i \le p}}$, where secret key \textcolor[rgb]{0.1,0.7,0.2}{$s{k_{w{'_i}}} = g(y,w{'_i})$}
				\item<5-> insert extra $\tau \left| W \right| - \left| {\cal I} \right|$ dummy entries(using random values) in $\cal I$ for padding.
				\item<6-> randomly shuffles $\cal I$, outsources $\cal I$, encrypted $C$ to cloud.
			\end{enumerate}
		\end{exampleblock}
	\end{frame}

\begin{frame}{The Basic Scheme}
	\begin{alertblock}<2->{Searching phase(the user)}
		\begin{enumerate}
			\item<3-> generates ${{S_{w,d}}}$ from input $w$ via Algorithm 1 and derives ${T_{w'}} = (\textcolor{red}{f(x,w')},\textcolor[rgb]{0.1,0.7,0.2}{g(y,w'))}$ for each $w' \in {S_{w,d}}$
			\item<4-> generates $\tau  - \left| {{S_{w,d}}} \right|$ dummy trapdoors by randomly choosing $j$ from ${\left\{ {\textcolor{red}{f(x,j)},\textcolor[rgb]{0.1,0.7,0.2}{g(y,j)}} \right\}_{1 \le j \le \tau \left| W \right| - \left| {\cal I} \right|}}$
			\item<5-> Cloud server compares all received trapdoors $\left\{ \textcolor{red}{f(x,w')} \right\}$(and $\left\{ \textcolor{red}{f(x,j)} \right\}$) with ${\cal I}$ uses the corresponding $\left\{ \textcolor[rgb]{0.1,0.7,0.2}{g(y,w')} \right\}$ to decrypt the matched entries,  and returns the union of file identifiers, ${\left\{ {FI{D_{{w_i}}}} \right\}_{ed(w,{w_i}) \le d}}$.
			\item<6-> The user retrieves and decrypts the files of interest.
		\end{enumerate}
	\end{alertblock}
	\begin{block}<7->{Improvement}
		Storage and search cost is ${\cal O}(\textcolor{red}{\tau} \left| W \right|)$.\\
		Bloom Filters can be introduced in to reduce the searching cost to  ${\cal O}( \left| W \right|)$
	\end{block}
\end{frame}

\section{The Symbol-based Trie-Traverse Searching Schema}

\begin{frame}{The Symbol-based Trie-Traverse Searching Schema}
	\begin{block}{All similar words in the trie can be found by a depth-first search}
		Construct a \textcolor{blue}{multi-way} tree for storing the similarity keyword elements over a finite symbol set. All trapdoors sharing a \textcolor{blue}{common prefix} have a common node. The root is associated with an empty set. 
	\end{block}
	\begin{columns}
		\column{0.45\textwidth}
    \begin{figure}
      \includegraphics[width=\textwidth]{fig2.jpg}
      \caption{The depth of the tree is $l/\theta$}
    \end{figure}
    \column{.45\textwidth}
    \begin{exampleblock}<2->{}
    	\begin{itemize}
    		\item Assume $\Delta  = \left\{ {{\alpha _i}} \right\}$ is a predefined symbol set.
    		\item $\left| \Delta  \right| = {\textcolor[rgb]{0.1,0.7,0.2}{2}^\theta }$
    		\item each symbol ${\alpha _i} \in \Delta $ is denoted by a $\theta$-bit \textcolor[rgb]{0.1,0.7,0.2}{binary} vector.
    		\item $l$ is the output length of one-way function $f(key, \cdot )$.
    	\end{itemize}
    	
    \end{exampleblock}
    \end{columns}
\end{frame}

\begin{frame}{The Symbol-based Trie-Traverse Searching Schema}
		\begin{columns}
			\column{.49\textwidth}
			\begin{exampleblock}<2->{Preprocessing phase(the owner)}
		\begin{enumerate}
			\item<3-> 	computes \textcolor{red}{${f(x,w{'_i})}$} for each ${w{'_i} \in {S_{{w_i},d}}}$,${1 \le i \le p}$ together with dummy entries.
			\item<4-> divides them into symbols as ${\alpha _{{i_1}}} \cdots {\alpha _{{i_{l/\theta }}}}$ from $\Delta$.
			\item<5-> builds up a trie ${G_W}$ covering all ${w_i} \in W$.
			\item<6-> attaches ${\left\{ {Enc(\textcolor[rgb]{0.1,0.7,0.2}{s{k_{w{'_i}}}},FI{D_{{w_i}}})} \right\}_{w{'_i} \in {S_{{w_i},d}},1 \le i \le p}}$ to $G_W$,\\outsourced it\\ with encrypted collection $C$ to the cloud.
			
			
		\end{enumerate}
			\end{exampleblock}
			
			\column{.44\textwidth}
			\begin{alertblock}<7->{Searching phase(the user)}
			 \begin{enumerate}
			 	\item<8-> sends a set of $\tau $ trapdoors(research request): ${\left\{ {{T_{w'}}} \right\}_{w' \in {S_{w,d}}}}$ and $\tau  - \left| {w' \in {S_{w,d}}} \right|$ dummy trapdoors.
			 	\item<9-> the cloud server divides each \textcolor{red}{$f(x,w')$} into a sequence of symbols from $\Delta$. Perform the search over the trie $G_W$.
			 	\item<10-> decrypts matches entries via \textcolor[rgb]{0.1,0.7,0.2}{$g(y,w')$} and returns ${\left\{ {FI{D_{{w_i}}}} \right\}_{ed(w,{w_i}) \le d}}$ to the user.
			 \end{enumerate}
			\end{alertblock}
		\end{columns}
\end{frame}

\begin{frame}{The Symbol-based Trie-Traverse Searching Schema}
	\begin{figure}
		\includegraphics[width=0.5\textwidth]{algo2.jpg}
	\end{figure}
     The search cost at the server side is only \textcolor{red}{${\cal O}(1)$} (a \textcolor{red}{constant} related to $l/\theta$).
\end{frame}

\section{Security Analysis}

\begin{frame}{Security Gurantee}
	\begin{block}<2->{}
		\begin{itemize}
			\item Our searching mechanism always returns the \textcolor{bazaar}{same} search results for the \textcolor{bazaar}{same} search requests.
			\item The cloud server can build up \textcolor[rgb]{0.0, 0.26, 0.15}{access patterns} and \textcolor[rgb]{0.0, 0.26, 0.15}{search patterns} along the interactions with users.
		\end{itemize}
	\end{block}
	
	\begin{alertblock}<3->{}
		Thus, the security guarantee should ensure that nothing beyond the \textcolor[rgb]{0.0, 0.26, 0.15}{pattern} and
		\textcolor[rgb]{0.0, 0.26, 0.15}{the outcome of a series of search requests} be leaked.
	\end{alertblock}
	\begin{block}<4->{The \textcolor{red}{non-adaptive} semantic security guarantee}
		The \textcolor{red}{non-adaptive} attack model only considers adversaries (i.e., the cloud server) that \textcolor{red}{cannot choose} search requests based on the trapdoors and search outcomes of previous searches. (Since only users with authorized secret keys can generate search trapdoors.)
	\end{block}
\end{frame}

\begin{frame}{Notations}
\begin{description}
	\item<2->[History] an interaction between the user and the cloud
	server, determined by a file collection $C$ and a set of keywords
	searched by the user, denoted as ${H_q} = (C,{w^1}, \ldots ,{w^q})$.
	\item<3->[View] given a history ${H_q}$ under some secret key $K$, the cloud
	server can only see an encrypted version of the history, i.e., the
	view ${V_K}({H_q})$, including: the index $\cal I$ of $C$; the trapdoors of the
	queried keywords ${\left\{ {{T_{w'}}} \right\}_{w' \in \left\{ {{S_{{w^1},d}}, \ldots ,{S_{{w^q},d}}} \right\}}}$ ; and the encrypted
	file collection of $C$, denoted as $\left\{ {{e_1}, \ldots ,{e_n}} \right\}$.
	\item<4->[Trace] given a history ${H_q}$ and an encrypted file collection $C$, the trace of ${Tr({H_q})}$ captures the precise information to be learned by cloud server, including: the size of the encrypted files $\left\{ {\left| {{F_1}} \right|, \ldots ,\left| {{F_n}} \right|} \right\}$; the outcome of each search, ${\left\{ {FI{D_{{w_i}}}} \right\}_{ed({w_i},{w^j}) \le d}}$ for $1 \le j \le q$; and the pattern ${\prod_q}$ for each search. Here ${\prod_q}$ is a symmetric matrix where the entry ${\prod _q}[i,j]$ stores the intersection ${\left\{ {{T_{w'}}} \right\}_{w' \in {S_{{w^i},d}} \cap {S_{{w^j},d}}}}$.
\end{description}
\end{frame}

\begin{frame}{Security Analysis}
	\begin{exampleblock}<2->{Security Strength}
		Given two histories with the identical trace, the cloud server is not able to \textcolor{red}{distinguish} the views of the two histories.\\
		In other words, the cloud server cannot extract additional knowledge beyond the information we are willing to leak (i.e., the trace) and thus our mechanism is secure.
	\end{exampleblock}
	\begin{theorem}<3->
		Our similarity keyword search schemes meet the \textcolor{red}{non-adaptive} semantic security.
	\end{theorem}
	\begin{exampleblock}<4->{}
		Due to space limitation, we only give the proof for the basic approach.\\
		The proof of other schemes follow similarly.
	\end{exampleblock}
	
\end{frame}

\begin{frame}{Proof}
	\begin{definition}[Simulator $\cal S$]
		Given ${Tr({H_q})}$, it can simulate a view $V_q^*$ indistinguishable from cloud server's view ${V_K}({H_q})$ with probability negligibly close to 1, for any $q \in \mathbb{N}$, any ${H_q}$ and randomly chosen $K$.
	\end{definition}
	\begin{itemize}
		\item<2-> $l$: the security parameter of the PRF $f(key, \cdot )$ \textcolor{blue}{(output length)}
		\item<3->  $\tau  = \max {\left\{ {\left| {{S_{{w_i},d}}} \right|} \right\}_{{w_i} \in W}}$
		\item<4-> $\left| W \right|$, and size of padded ${FI{D_{{w_i}}}}$ are known to $\cal S$	
	\end{itemize}
\end{frame}

\begin{frame}{Proof}
	\begin{itemize}
	\item<1-> For $q=0$, $\cal S$ builds $V_0^* = \left\{ {e_1^*,e_2^*, \ldots ,e_n^*,{{\cal I}^*}} \right\}$ such that $e_i^*$ is randomly chosen from ${\left\{ {0,1} \right\}^{\left| {{F_i}} \right|}}$ for $1 \le i \le n$.
	\item<2-> Let ${{\cal I}^*} = ({T^*},{C^*})$.\\
	${T^*}[i]$ and ${C^*}[i]$ : the $i$-th row entry in ${T^*}$ and ${C^*}$.
	\begin{itemize}
		\item<3-> To generate ${T^*}$,for $1 \le i \le \tau \left| W \right|$, $\cal S$ selects a random $t_i^* \in {\left\{ {0,1} \right\}^l}$, and sets ${T^*}[i] = t_i^*$.
		\item<4-> To generate ${C^*}$,for $1 \le i \le \tau \left| W \right|$, $\cal S$ selects a random $c_i^* \in {\left\{ {0,1} \right\}^{\left| {FI{D_{{w_i}}}} \right|}}$, and sets ${C^*}[i] = c_i^*$.
	\end{itemize}
	\item<5-> Due to the semantic security of the symmetric encryption, no probabilistic polynomial-time \textcolor{grey}{(P.P.T.)} adversary can distinguish between ${e_i}$ and $e_i^*$, or between ${Enc(s{k_{w{'_i}}},FI{D_{{w_i}}})}$ and $c_i$.
	\item<6-> Also due to the pseudo-randomness of the trapdoor function, no \textcolor{grey}{P.P.T.} adversary can distinguish between $f(x,w{'_i})$ and a random string \textcolor{red}{$t_i^*$}.
	\item<7-> Thus, ${V_K}({H_0})$and $V_0^*$ are \textcolor{red}{indistinguishable}.
\end{itemize}
\end{frame}

\begin{frame}{Proof}
	\begin{itemize}
		\item<1-> 	For $q \ge 1$, $\cal S$ builds $V_q^* = \left\{ {e_1^*,e_2^*, \ldots ,e_n^*,{{\cal I}^*},{{\left\{ {T_{w'}^*} \right\}}_{w' \in \left\{ {{S_{{w^1},d}}, \ldots ,{S_{{w^q},d}}} \right\}}}} \right\}$
				\begin{itemize}
					\item $e_i^*$ is still randomly drawn from ${\left\{ {0,1} \right\}^{\left| {{F_i}} \right|}}$ for $1 \le i \le n$.
				\end{itemize}
		\item<2-> Let ${{\cal I}^*} = ({T^*},{C^*})$.
        \item<3-> the result ${\left\{ {FI{D_{{w_i}}}} \right\}_{ed({w_i},{w^j}) \le d}}$ for the $j$-th search request is the union of file identifiers in the matched entries of the index
		\begin{itemize}
			\item<4-> ${\left\{ {FI{D_{{w_i}}}} \right\}_{ed({w_i},{w^j}) \le d}}$ can be rewritten as $\bigcup\nolimits_{k = 1}^{{\alpha _j}} {FI{D_{{w_{j,k}}}}} $
			\item<5-> ${\alpha _j}$ denotes the number of matches for the $j$-th search
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Proof}
	\begin{itemize}
		\item To build the first trapdoor set ${\left\{ {T_{w'}^*} \right\}_{w' \in \left\{ {{S_{{w^1},d}}} \right\}}}$ for search input $w^1$,the simulator $\cal S$ does the following:
		\begin{itemize}
			\item<2-> Select ${\alpha_1}$ random strings $t_{1,1}^*, \ldots ,t_{1,{\alpha _1}}^* \in {\left\{ {0,1} \right\}^l}$ and set them to ${\alpha _1}$ non-assigned entries ${T^*}[{i_{1,1}}], \ldots ,{T^*}[{i_{1,{\alpha _1}}}]$.
			\item<3-> Select ${\alpha_1}$ random strings $\rho _{1,1}^*, \ldots \rho _{1,{\alpha _i}}^* \in {\left\{ {0,1} \right\}^l}$ and set ${C^*}[{i_{1,k}}] = Enc(\rho _{1,k}^*,FI{D_{{w_i},k}})$ for $1 \le k \le {\alpha _1}$
			\item<4-> Set remaining $\tau  - {\alpha _1}$ trapdoors as random value pairs
			$(t_{1,k}^*,\rho _{1,k}^*) \in {\left\{ {0,1} \right\}^l} \times {\left\{ {0,1} \right\}^l}$ for ${\alpha _1} \le k \le \tau $ .
		\end{itemize}
		\item<5-> For trapdoor simulation of $w^j$ for $2 \le j \le q$, if $\left| {{\prod _q}[i,j]} \right| = 0$ for all $i < j$, the simulator repeats the same process as
		simulating trapdoors for $w^1$.
		\item<6-> Otherwise, let ${\beta _j}$ denotes the number of file identifier list in ${\left\{ {FI{D_{{w_j},k}}} \right\}_{1 \le k \le {\alpha _j}}}$, which have
		been assigned already in ${\left\{ {FI{D_{{w_i},k}}} \right\}_{1 \le k \le {\alpha _i},i < j}}$.
	\end{itemize}
\end{frame}

\begin{frame}{Proof}
	Next, $\cal S$ does:
	\begin{itemize}
		\item<2-> Choose ${\beta _j}$ trapdoors from existing ${\left\{ {T_{w'}^*} \right\}_{w' \in \left\{ {{s_{{w^i},d}}} \right\},i < j}}$ that match to the common ${\beta _j}$ file identifier list of ${\left\{ {FI{D_{{w_j},k}}} \right\}_{1 \le k \le {\alpha _j}}} \cap (\bigcup\nolimits_{i = 1}^{j - 1} {{{\left\{ {FI{D_{{w_i},k}}} \right\}}_{1 \le k \le {\alpha _i}}}} )$, and assign them to trapdoor simulation of $w^j$.
		\item<3-> If $\alpha_j > \beta_j$, the simulator $\cal S$ builds $\alpha_j - \beta_j$ entries in ${{{\cal I}^*}}$ via the same process as simulating trapdoors for $w^1$.
		\item<4-> $\cal S$ further checks ${{\prod _q}[i,j]}$ for $i < j$, finds from already generated ${\left\{ {T_{w'}^*} \right\}_{w' \in \left\{ {{s_{{w^i},d}}} \right\},i < j}}$ the common ${\gamma _j}$ trapdoors that do not have matched entries in index ${{{\cal I}^*}}$, and assigns them to the current trapdoor simulation of $w^j$.
		\item<5-> Set remaining $\tau  - {\alpha _j} - {\gamma _j}$ trapdoors as random value pairs from ${\left\{ {0,1} \right\}^l} \times {\left\{ {0,1} \right\}^l}$.
 \end{itemize}
\end{frame}

\begin{frame}{Proof}
	Thus
	\begin{proof}<2->
		\begin{itemize}
			\item<3-> The correctness of the constructed view is easy to demonstrate by searching on ${{{\cal I}^*}}$ via ${\left\{ {T_{w'}^*} \right\}_{w' \in {s_{{w^i},d}}}}$ for each $i$.
			\item<4-> There is no \textcolor{grey}{P.P.T.} adversary can \textcolor{red}{distinguish} between $V_q^*$ and ${V_K}({H_q})$
			\item<5-> In particular, the simulated encrypted ciphertext
			is indistinguishable due to the \textcolor{blue}{semantic security of the
			symmetric encryption}.
			\item<6-> The indistinguishability of index and trapdoors is based on the indistinguishability of the \textcolor{blue}{pseudorandom function output} and a \textcolor{blue}{random string}.
		\end{itemize}
	\end{proof}
\end{frame}

\section{Scheme Evaluation}

\begin{frame}{Scheme Evaluation}
	\begin{table}
		\begin{tabular}{l l l l}
			\toprule
			{} & \textbf{SSE} & \textbf{Basic} & \textbf{Trie-traverse}\\
			\midrule
			 \textbf{Preprocessing} & ${\cal O}(\left| W \right|)$ & ${\cal O}(\tau \left| W \right|)$ & ${\cal O}(\tau \left| W \right|)$ \\
			 \textbf{Index size} & ${\cal O}(\left| W \right|)$ & ${\cal O}(\tau \left| W \right|)$ & ${\cal O}(\tau \left| W \right|)$ \\
			 \textbf{Search cost} & ${\cal O}(1)$ & ${\cal O}(\tau \left| W \right|)$ & \textcolor{red}{${\cal O}(1)$}  \\
			 \textbf{Similarity search} & No & Yes & Yes \\
			\bottomrule
		\end{tabular}
		\caption{Comparison of SSE schemes}
	\end{table}

\end{frame}

\section{Experiment}

\begin{frame}{Experiment}
		\begin{block}<2->{Experiment Design}
			\begin{itemize}
				\item A real data set: RFC, 5,731 plaintext files, 277MB
				\item C programming language 
				\item Local workstation
				\item Cloud side:Amazon Elastic Computing Cloud(EC2)
			\end{itemize}
		\end{block}
		\begin{exampleblock}<3->{Note}
			In our experiment the dominant factor affecting the performance is th number of \textcolor{red}{unique keywords} to be indexed, not the \textcolor[rgb]{0.1,0.7,0.2}{file collection size}.
		\end{exampleblock}
\end{frame}

\begin{frame}{Cost for Generating Similarity Keyword Set}
	\begin{figure}
        \includegraphics[width=0.8\textwidth]{subfig1.jpg}
        \caption{Similarity set construction time using wildcard-based approach with different choices of edit distance $d$}
	\end{figure}
	\begin{block}<2->{}
		The construction time increases \textcolor{blue}{linearly} with the number of keywords.
	\end{block}
\end{frame}

\begin{frame}{Cost For Building Searchable Index}
    \begin{columns}
    	\column{.45\textwidth}
	\begin{figure}
		\includegraphics[width=\textwidth]{subfig2.jpg}
		\caption{Time cost for searchable index construction with different choices of edit distance $d$}
	\end{figure}
	\column{.5\textwidth}
	    \begin{alertblock}<2->{}
	    	For completeness, we also include the index building time of existing SSE as a \textcolor{red}{baseline} for comparison here.
	    \end{alertblock}
	    \begin{exampleblock}<3->{}
	    	The whole index construction is just a one-time cost and can be conducted off-line
	    \end{exampleblock}
	\begin{block}<4->{}
		Similar to the similarity keyword set construction, the index construction time increases \textcolor{blue}{linearly} with the number of distinct keywords.
	\end{block}
	\end{columns}
\end{frame}

\begin{frame}{Cost For Building Searchable Index}
	\begin{columns}
		\column{.45\textwidth}
	\begin{figure}
		\includegraphics[width=\textwidth]{subfig3.jpg}
		\caption{Storage cost for searchable index construction with different choices of edit distance $d$}	
	\end{figure}
	\column{.5\textwidth}
	\begin{exampleblock}<2->{}
		Again, our approach consumes more storage space than the baseline due to the \textcolor[rgb]{0.1,0.7,0.2}{multi-way tree structure} and the \textcolor[rgb]{0.1,0.7,0.2}{additional entries} in the index corresponding to the similarity keywords
	\end{exampleblock}
	\begin{block}<3->{}
		But can be deemed as \textcolor{blue}{reasonable} cost of supporting similarity search
	\end{block}
	\begin{alertblock}<4->{}
		"Average keyword length" also \textcolor{red}{sightly} influence the time and space cost of building searchable index.
	\end{alertblock}
	\end{columns}
\end{frame}

\begin{frame}{Cost For Searching the Index}
	\begin{figure}
		\includegraphics[width=.75\textwidth]{subfig4.jpg}
		%\caption{Evaluation for search cost and file retrieval}
	\end{figure}
	\begin{block}<2->{}
		The proposed  mechanism cost \textcolor{blue}{constant} search time.
	\end{block}
	\begin{exampleblock}<3->{}
		Cost for results retrieval and decryption is plainly determined by the \textcolor[rgb]{0.1,0.7,0.2}{number} of retrieved results
	\end{exampleblock}
\end{frame}


%------------------------------------------------
\section{The End}
\begin{frame}{The End}
\Huge{\centerline{Thanks}}
\end{frame}

%----------------------------------------------------------------------------------------

\end{document} 